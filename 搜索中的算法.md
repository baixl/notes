[TOC]
### 1、 排序算法
#### 1.1、排序模型概念&评价指标

#### 1.2、GBRANK
>两篇不错的文档
>1、https://www.bbsmax.com/A/E35pM70Ldv/
>2、https://mlnote.com/2016/09/18/gbRank-logsitRank-from-up-to-bottom/


gbrank是一种pair-wise算法，其拟合的是url（文档）的先后关系。gbrank将排序问题转化成回归问题，通过gbdt的方式求解
一个pair是指一个query-url对， 记`query-url1为x, query-url2为y`， 当用户发起query时， `x>y` 表示`x`更适合用户需求，反之`y`更适合。

训练集表示为
 $$S=\{<x_i, y_i> | x_i > y_i, i=i...N \}$$

假设给定排序函数f , 当$x_i >y_i$ 有 $f(x_i) \geq f(y_i)$。则可以定义损失函数
$$L(f) = \frac{1}{2} \sum_{i=1}^{N} max(0, f(y_i) - f(x_i))^2$$

这个损失函数可以理解为， 当偏序关系关注用户需求时($x_i > y_i$), 对应的损失为0， 否则损失为$[0, f(y_i) - f(x_i)]^2$。 通常 ，为避免$f$是一个常量，需要在loss上加一个平滑项目$0<\tau \leq0 $ ， 也可以认为，$f(x)$与$f(y)$的差距达到$\tau$时，其损失才会为0。
$$L(f) = \frac{1}{2} \sum_{i=1}^{N} max(0, f(y_i) - f(x_i) + \tau)^2$$ 

当定义了loss函数，就变成了如何最小化这个loss。

todo： 梯度求解

#### 1.2、RankSVM

### 2、 聚类算法
#### 2.1、query的聚类
根据展现或者点击日志下的query挖掘，可以挖掘出query在历史行为中，更关心的语义是什么。
举个例子：
```
1、当香港暴动事件时
q=香港， 点击了 url1：香港暴动游行
q=香港游行， 点击了url1
q=香港暴动， 点击了url1

另外一个例子：
在没有真实突发事件时， 也可以通过点击关系，来挖掘query在一段时间（一个月、半年、一年内）的真实需求，
q=黑洞， 点击了url1：霍金发表文章讲述黑洞，天文理论
q=霍金， 点击了url1：霍金发表文章讲述黑洞，天文理论
q=量子力学， 点击了url1：霍金发表文章讲述黑洞，天文理论

这个时候，用户搜索黑洞时，就更应该出 霍金，天文相关的知识。而不是出一个 叫黑洞的 显示器的结果。

```
通过这种共现的点击关系，其实就能挖掘出每个query到底关心的是什么事件， 或者一段时间内的真实需求（从统计上来讲）。这个在时效性或者相关性维度上，能够真实反映出用户的需求。
通过这种q-u相关的挖掘，动态刻画出了query一段时间内的真实需求。

挖掘流程也很简单, 大体思路是：
```
1、解析一段时间的线上点击/展现日志， 解析出所有的q-u点击关系
这里也可以通过用户的seesion 数据来获取（一般从session日志下就能拿到）
输出：按行一行行输出就好
q1-u1 、q2-u1、q1-u2、q2-u2
这里就能看到同一个url的共现query是啥了

2、将共同的点击的query merge到一块， 输出q-q共现关系， 以及共现频次

将上面的 q1-q2这种共现关系拿出来， 频次是用来刻画共现强度

3、将所有q-q关系排序
按照第一个q排序，那就能找到所有与她相关的共现q，以及共现频次。

4、从所有共现q中 统计出核心词
```

#### 2.1、doc的聚类
> 论文：Clustering by fast search and find of density peaks via HD

doc端的聚类，也可以挖掘出当前召回的url中，真实的事件需求是什么。

todo

### 3、 nn模型的应用
#### 3.1、 文本分类

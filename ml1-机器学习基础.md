
# 机器学习基础
> 该系列将整理机器学习相关知识。这篇博客主要讨论:
> 1 机器学习基本概念
> 2 模型评估与选择
> 3 正则化和交叉验证
> 4 偏差与方差

## 1 机器学习基本概念
A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.在实际中，经验E通常以数据形式存在，T表示机器学习模型(分类回归强化等)，P表示机器学习评价指标。
机器学习可以分为监督学习、非监督学习、半监督学习以及强化学习。监督学习按照目标值和样本空间的关系，又可以分为分类(`LR`，`感知器`，`决策树`，`svm`，`集成学习：随机森林、GBDT`等)和回归(`线性回归`、`SVR`、`CART`，`集成学习：随机森林、GBDT`等)。无监督学习常见的有聚类、降维、异常值判定等。
<!--more-->
## 2 模型评估与选择
通常，我们会为机器学习问题定义一个优化目标，常见的目标是定义一个模型的损失函数或者叫做风险函数，通过数学优化方法，求解最小的损失函数。常见的损失函数有：

* 0-1 损失函数
* 平方损失函数

$$L(Y,f(x))=(Y-f(X))^2$$
* 绝对损失函数

$$L(Y,f(x))=|Y-f(x)|$$
* 对数损失函数

$$L(Y,f(x))=-logP(Y|X)$$
 
损失函数值越小，模型就越好。机器学习优化的目标就是使用一定的数学优化方法，尽可能较低损失函数。
模型的评估方法常用交叉验证。

1. 将数据集分成两部分（8：2或者：3：1），分成训练集和测试集，训练集用于训练模型，测试集用于模型评估繁华误差
2. 将训练集按照n折交叉的方式用于训练，通常需要进行网格搜索的方式用于评估超参数
3. 在训练集上训练的模型，用于在测试集中，计算模型的评价指标。

对分类问题，常见的模型评估指标有：

* 准确率
* 召回率
* F1值
* ROC
* AUC

通常，以关注的类为正类，其他类为负类，分类器在测试集上预测正不正确，可以分4种情况：

* TP：将正类预测为正类
* FN：将正则预测为负类
* FP：将负类预测为正类
* TN：将负类预测为负类

则准确率定义为：

$$P=\frac{TP}{TP+FP}$$ 

召回率定义为：

$$R=\frac{TP}{TP+FN}$$ 

一般来说，准确率和召回率是一对矛盾的量，准确率高，召回率往往偏低，召回率搞，准确率往往偏高。对于不同的问题，可能会依据实际情况更加看重准确率或者召回率。

$F_1$值是准确率和召回率的调和平均值：

$$\frac{2}{F_1}=\frac{1}{P} + \frac{1}{R}$$

另外两个指标可以参考博客：[roc and auc](http://alexkong.net/2013/06/introduction-to-auc-and-roc/)
## 3 欠拟合、过拟合及其解决办法
所谓欠拟合、就是当模型一开始训练时，还没有充分学习到数据中的特征，导致模型对数据的描述不太好。而过拟合，则是指模型过度学习了数据中的特征，比如个别数据的误差导致的特征，使得模型的泛化能力不好。下图中左一、右一分别代码欠拟合和过拟合的情况。
![欠拟合与过拟合](https://img-blog.csdn.net/20180428101514985?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hfbGluZ2JhaQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
从交叉验证来讲，过拟合时模型在训练集上的误差很小，在验证集上误差却很大。对欠拟合，训练集和测试集上误差都很大。

**如何来判断一个模型是欠拟合和过拟合呢?**  
用学习曲线。
![](https://img-blog.csdn.net/20180428101847964?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hfbGluZ2JhaQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
采用交叉验证的方式。这里介绍下方差、偏差的概念。模型`Error = Bias + Variance`，Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的`精准度`，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的`稳定性`。
通过学习曲线，可以根据J_cv和J_train的差异来判断欠拟合还是过拟合。

* 当J_cv很大时，(图中两个蓝色点)，模型存在欠拟合和过拟合。
* 当J_cv很大时，且J_cv >> J_train，且J_train较小时，模型存在过拟合
* 当J_cv很大时，且J_cv和J_train差不多，且J_tran很大时，模型存在欠拟合

## 4 如何解决欠拟合、过拟合？
那么如何解决欠拟合、过拟合呢？
（1）解决欠拟合的方法

```
1. 增加特征，比如特征组合、高次特征
2. 添加非线性特征，比如SVM、决策树、DNN等
3. 如果有正则项，减少正则化参数
4. Boosting方式，Boosting关注的是降低偏差
5. DNN中的Dropout
```
（2）解决过拟合的方法

```
1. 重新清洗数据，导致过拟合可能时因为数据不纯
2. 增大样本量
3. 采用正则化项，常见正则化有L1(Lasso)，L2(Ridge),其中Lasso对于稀疏特征更好，有助于自动筛选特征
4. 降低模型复杂度，比如取消高次项
```

## 4 参考
* 李航《统计学习方法》
* 周志华《机器学习》

